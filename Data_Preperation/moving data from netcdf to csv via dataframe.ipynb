{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Constant values\n",
    "lat = 71.323\n",
    "lon = -156.609\n",
    "alt = 8m\n",
    "\n",
    "# Moving the ARM solar data from the netcdf originator files to csv files for further process\n",
    "##Current file is nsaarmbecldradC1.c1.20060101.000000.cdf\n",
    "This file contain hourly data covering the period of a year.\n",
    "Out of it I am taking the following variables.\n",
    "tot_cld : Total Cloud Fraction based on MMCR/MPL (satille names), narrow field-of-view, hourly mean\n",
    "swdn : Surface Downwelling Shortwave Hemispheric Irradiance, best estimate, hourly mean\n",
    "pmv : Precipitable water vapor best-estimate value, hourly mean\n",
    "lwp : Liquid water path best-estimate value, hourly mean\n",
    "\n",
    "\n",
    "\n",
    "All of the following variables names end in the satillie that the data originates from\n",
    "\n",
    "TSI, ~30s data\n",
    "tot_cld_tsi : Total Cloud Fraction, from Total Sky Imager, 100 degree FOV,  hourly mean\n",
    "\n",
    "GOES, NASA - Langley VISST product, 30min data\n",
    "cld_low_sat_VISST : Satellite-measured low level cloud, clouds below 2 km\n",
    "cld_mid_sat_VISST : Satellite-measured middle level cloud, clouds between 2 and 6 km\n",
    "cld_high_sat_VISST : Satellite-measured high level cloud, clouds above 6 km\n",
    "tot_cld_sat_VISST : Satellite-measured total cloud\n",
    "cld_thick_sat_VISST : Satellite-measured cloud thickness\n",
    "cld_top_sat_VISST : Satellite-measured cloud top\n",
    "\n",
    "Terra & Aqua, NASA-Langley CRS product, 1x1 degree data\n",
    "cld_low_sat_CERES : Low level clouds, satellite-measured, clouds below 2 km\n",
    "cld_mid_sat_CERES : Middle level clouds, satellite-measured, clouds between 2 and 6 km (including 2 and 6 km)\n",
    "cld_high_sat_CERES : High level clouds, satellite-measured, clouds above 6 km\n",
    "tot_cld_sat_CERES : Total cloud,satellite-measured\n",
    "\n",
    "The following data is two dimensional and had to be removed when importing from netcdf \n",
    "for usablity. I also did not think that having the increaed amount of data would be helpful\n",
    "for processing time. \n",
    "\n",
    "cld_frac\n",
    "cld_frac_MMCR\n",
    "cld_frac_MPL\n",
    "qc_cld_frac\n",
    "base_time\n",
    "time_offset\n",
    "time_bounds\n",
    "\n",
    "### New note: I have just noticed that I have a limit of 6 years of data for these files. The other files have the full 10 years of data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# To export to csv and join the data together\n",
    "import pandas as pd\n",
    "# Used to import the netcdf file. Removed uneeded data. Then transfer data to pd.DataFrame\n",
    "import xarray as xr\n",
    "file = '/home/nelson/PycharmProjects/Solar Forecasting Thesis Project/Data_Preperation/test exploration/nsaarmbecldradC1.c1.20060101.000000.cdf'\n",
    "ds = xr.open_dataset(file, drop_variables=[\"cld_frac\", \"cld_frac_MMCR\", \"cld_frac_MPL\",\n",
    "                                             \"qc_cld_frac\", \"time_bounds\", \"time_offset\",\n",
    "                                             \"time_bounds\"])\n",
    "df = ds.to_dataframe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Current file is nsaarmbecldradC1.c1.20060101.003000.nc\n",
    "This data is simaliar the the above data. Main differences are that the cloud data is not\n",
    "seperated by satillite type. It also has the skycover variable.\n",
    "\n",
    "skycover : Fractional sky cover, based on shortwave flux, hourly mean. The angular portion of the sky \n",
    "view that contains clouds divided by the total angular hemispheric view, which is estimated\n",
    " from the ARM broadband SW radiometer measurements using the Hemispheric Sky Imager (HIS) and \n",
    " diffuse cloud effect regression relationship described in Long et al.\n",
    "  1999 (http://science.arm.gov/~clong/SkyCov_art/1999radC.htm).\n",
    "\n",
    "\n",
    "For some reason the time stamps are not converting over. So I have to convert the \n",
    "base time to something useable. Which means translating the int that base time is in to seconds\n",
    "where the date is seconds since 1970-1-1 0:00:00 0:00."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file2 = \"/home/nelson/PycharmProjects/Solar Forecasting Thesis Project/Data_Preperation/test exploration/nsaarmbecldradC1.c1.20060101.003000.nc\"\n",
    "# variables are dropped if they are not needed to save space and avoid 2 dimensional data\n",
    "ds2 = xr.open_dataset(file2, drop_variables=[\"cld_frac\", \"cld_frac_MPL\", \"cld_base_source_status\",\n",
    "                                             \"qc_tot_cld\", \"swdif\"\n",
    "                                             \"qc_cld_frac\", \"time_bounds\", \"time_frac\",\n",
    "                                             \"source_cld_frac\", \"height\", \"stdev_sedif\"\n",
    "                                            \"cld_frac_radar\", \"time\", \"qc_swdif\",\n",
    "                                             \"swdir\", \"stdev_swdir\", \"qc_swdir\",\n",
    "                                             \"swup\", \"stdev_swup\", \"qc_swup\",\n",
    "                                             \"lwdn\", \"stdev_lwdn\", \"qc_lwdn\",\n",
    "                                             \"lwup\", \"stdev_lwup\", \"qc_lwup\",\n",
    "                                             \"lw_net_TOA\",\n",
    "                                             \"sw_net_TOA\", \"sw_dn_TOA\", \"totswfluxdn\",\n",
    "                                             \"qc_totswfluxdn\", \"stdev_totswfluxdn\", \"alt\",\n",
    "                                             \"lat\", \"lon\"], decode_times=False)\n",
    "df2 = ds2.to_dataframe()\n",
    "\n",
    "# Add base time (seconds since 1970-1-1 0:00:00 0:00) which in 2006 Jan 1st in this case\n",
    "# and the time offset. This will get me a useable timestamp in time_offset that \n",
    "# I can make into a datetime \n",
    "df2[\"time_offset\"] = df2[\"time_offset\"] + df2[\"base_time\"]\n",
    "df2[\"time_offset\"] = pd.to_datetime(df2[\"time_offset\"], unit='s')\n",
    "\n",
    "# Dropping all unneeded columns from the DataFrame to save data\n",
    "drop_cols = [\"base_time\"]\n",
    "df2.drop(drop_cols, axis=\"columns\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Joining the data together for both of the above files\n",
    "This will work for both of the file types shown above.\n",
    "I have just done this for one of the files though to simplify the example.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# make a small test sample which in this case is another instance of the above df\n",
    "df1j = ds.to_dataframe()\n",
    "df_test = pd.concat([df, df1j])\n",
    "# show the shape of original dataframe\n",
    "print(df.shape)\n",
    "# show the shape after joining\n",
    "print(df_test.shape)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}