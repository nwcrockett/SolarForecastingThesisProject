{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Constant values\n",
    "lat = 71.323\n",
    "lon = -156.609\n",
    "alt = 8m\n",
    "\n",
    "# Moving the ARM solar data from the netcdf originator files to csv files for further process\n",
    "##Current file is nsaarmbecldradC1.c1.20060101.000000.cdf\n",
    "This file contain hourly data covering the period of a year.\n",
    "Out of it I am taking the following variables.\n",
    "tot_cld : Total Cloud Fraction based on MMCR/MPL (satille names), narrow field-of-view, hourly mean\n",
    "swdn : Surface Downwelling Shortwave Hemispheric Irradiance, best estimate, hourly mean\n",
    "pmv : Precipitable water vapor best-estimate value, hourly mean\n",
    "lwp : Liquid water path best-estimate value, hourly mean\n",
    "\n",
    "\n",
    "\n",
    "All of the following variables names end in the satillie that the data originates from\n",
    "\n",
    "TSI, ~30s data\n",
    "tot_cld_tsi : Total Cloud Fraction, from Total Sky Imager, 100 degree FOV,  hourly mean\n",
    "\n",
    "GOES, NASA - Langley VISST product, 30min data\n",
    "cld_low_sat_VISST : Satellite-measured low level cloud, clouds below 2 km\n",
    "cld_mid_sat_VISST : Satellite-measured middle level cloud, clouds between 2 and 6 km\n",
    "cld_high_sat_VISST : Satellite-measured high level cloud, clouds above 6 km\n",
    "tot_cld_sat_VISST : Satellite-measured total cloud\n",
    "cld_thick_sat_VISST : Satellite-measured cloud thickness\n",
    "cld_top_sat_VISST : Satellite-measured cloud top\n",
    "\n",
    "Terra & Aqua, NASA-Langley CRS product, 1x1 degree data\n",
    "cld_low_sat_CERES : Low level clouds, satellite-measured, clouds below 2 km\n",
    "cld_mid_sat_CERES : Middle level clouds, satellite-measured, clouds between 2 and 6 km (including 2 and 6 km)\n",
    "cld_high_sat_CERES : High level clouds, satellite-measured, clouds above 6 km\n",
    "tot_cld_sat_CERES : Total cloud,satellite-measured\n",
    "\n",
    "The following data is two dimensional and had to be removed when importing from netcdf \n",
    "for usablity. I also did not think that having the increaed amount of data would be helpful\n",
    "for processing time. \n",
    "\n",
    "cld_frac\n",
    "cld_frac_MMCR\n",
    "cld_frac_MPL\n",
    "qc_cld_frac\n",
    "base_time\n",
    "time_offset\n",
    "time_bounds\n",
    "\n",
    "### New note: I have just noticed that I have a limit of 6 years of data for these files. The other files have the full 10 years of data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# To export to csv and join the data together\n",
    "import pandas as pd\n",
    "# Used to import the netcdf file. Removed uneeded data. Then transfer data to pd.DataFrame\n",
    "import xarray as xr\n",
    "file = '/home/nelson/PycharmProjects/Solar Forecasting Thesis Project/Data_Preperation/test exploration/nsaarmbecldradC1.c1.20060101.000000.cdf'\n",
    "ds = xr.open_dataset(file, drop_variables=[\n",
    "            \"cld_frac\", \"cld_frac_MMCR\", \"cld_frac_MPL\",\n",
    "            \"qc_cld_frac\", \"time_bounds\", \"time_offset\",\n",
    "            \"time_bounds\", \"height\", \"base_time\",\n",
    "            \"lon\", \"lat\", \"qc_cld_frac_source\",\n",
    "            \"qc_cld_base_source\", \"swdif\", \"stdev_swdif\",\n",
    "            \"qc_swdif\", \"swdir\", \"stdev_swdir\",\n",
    "            \"qc_swdir\", \"swup\", \"stdev_swup\",\n",
    "            \"qc_swup\", \"lwdn\", \"stdev_lwdn\",\n",
    "            \"qc_lwdn\", \"lwup\", \"stdev_lwup\",\n",
    "            \"qc_lwup\", \"lwnet_TOA_sat_VISST\", \"swnet_TOA_sat_VISST\",\n",
    "            \"swdn_TOA_sat_VISST\", \"lwnet_TOA_sat_CERES\", \"swnet_TOA_sat_CERES\",\n",
    "            \"swnet_clr_TOA_sat_CERES\", \"lwnet_clr_TOA_sat_CERES\", \"swdn_TOA_sat_CERES\",\n",
    "            \"num_samples_sat_CERES\", \"source_sat_CERES\"\n",
    "        ])\n",
    "df = ds.to_dataframe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Current file is nsaarmbecldradC1.c1.20060101.003000.nc\n",
    "This data is simaliar the the above data. Main differences are that the cloud data is not\n",
    "seperated by satillite type. It also has the skycover variable.\n",
    "\n",
    "skycover : Fractional sky cover, based on shortwave flux, hourly mean. The angular portion of the sky \n",
    "view that contains clouds divided by the total angular hemispheric view, which is estimated\n",
    " from the ARM broadband SW radiometer measurements using the Hemispheric Sky Imager (HIS) and \n",
    " diffuse cloud effect regression relationship described in Long et al.\n",
    "  1999 (http://science.arm.gov/~clong/SkyCov_art/1999radC.htm).\n",
    "\n",
    "\n",
    "For some reason the time stamps are not converting over. So I have to convert the \n",
    "base time to something useable. Which means translating the int that base time is in to seconds\n",
    "where the date is seconds since 1970-1-1 0:00:00 0:00."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file2 = \"/home/nelson/PycharmProjects/Solar Forecasting Thesis Project/Data_Preperation/test exploration/nsaarmbecldradC1.c1.20060101.003000.nc\"\n",
    "# variables are dropped if they are not needed to save space and avoid 2 dimensional data\n",
    "ds2 = xr.open_dataset(file2, drop_variables=[\"cld_frac\", \"cld_frac_MPL\", \"cld_base_source_status\",\n",
    "                                             \"qc_tot_cld\", \"swdif\"\n",
    "                                             \"qc_cld_frac\", \"time_bounds\", \"time_frac\",\n",
    "                                             \"source_cld_frac\", \"height\", \"stdev_sedif\"\n",
    "                                            \"cld_frac_radar\", \"time\", \"qc_swdif\",\n",
    "                                             \"swdir\", \"stdev_swdir\", \"qc_swdir\",\n",
    "                                             \"swup\", \"stdev_swup\", \"qc_swup\",\n",
    "                                             \"lwdn\", \"stdev_wdn\", \"qc_lwdn\",\n",
    "                                             \"lwup\", \"stdev_lwup\", \"qc_lwup\",\n",
    "                                             \"lw_net_TOA\",\n",
    "                                             \"sw_net_TOA\", \"sw_dn_TOA\", \"totswfluxdn\",\n",
    "                                             \"qc_totswfluxdn\", \"stdev_totswfluxdn\", \"alt\",\n",
    "                                             \"lat\", \"lon\"], decode_times=False)\n",
    "df2 = ds2.to_dataframe()\n",
    "\n",
    "# Add base time (seconds since 1970-1-1 0:00:00 0:00) which in 2006 Jan 1st in this case\n",
    "# and the time offset. This will get me a useable timestamp in time_offset that \n",
    "# I can make into a datetime \n",
    "df2[\"time_offset\"] = df2[\"time_offset\"] + df2[\"base_time\"]\n",
    "df2[\"time_offset\"] = pd.to_datetime(df2[\"time_offset\"], unit='s')\n",
    "\n",
    "# Dropping all unneeded columns from the DataFrame to save data\n",
    "drop_cols = [\"base_time\"]\n",
    "df2 = df2.drop(drop_cols, axis=\"columns\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Joining the data together for both of the above files\n",
    "This will work for both of the file types shown above.\n",
    "I have just done this for one of the files though to simplify the example.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# make a small test sample which in this case is another instance of the above df\n",
    "df1j = ds.to_dataframe()\n",
    "df_test = pd.concat([df, df1j])\n",
    "# show the shape of original dataframe\n",
    "print(df.shape)\n",
    "# show the shape after joining\n",
    "print(df_test.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Current file is nsainterpolatedsondeC1.c1.20060101.000030.nc\n",
    "## This is the move from Hourly data to minute data\n",
    "\n",
    "I don't think that I can do anything with any of this data. It is all 2 dimensional data\n",
    "with a height variable to go with each time series recordings of the weather variables.\n",
    "This height variable extends to 332 sections of height. This is just way too much data. \n",
    "Right now for me this means that I will not do anything with this data.\n",
    "\n",
    "\n",
    "## Current file is nsaskyrad20sC1.a0.20060808.000000.cdf\n",
    "\n",
    "This is another file that I cannot do anything with. Data is only solar but all of the\n",
    "units are in mV rather than W/m^2. No other weather data is in these files. I really\n",
    "don't see any way to forecast or use this data. It is all also in 20 second time steps.\n",
    "\n",
    "\n",
    "## Current file nsametC1.b1.20060104.000000.cdf\n",
    "\n",
    "Minute time step data. May need to have the file joined with nsaradflux1longC1.c2.20060114.100000.nc.\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file3 = \"/home/nelson/PycharmProjects/Solar Forecasting Thesis Project/Data_Preperation/test exploration/nsametC1.b1.20060104.000000.cdf\"\n",
    "ds3 = xr.open_dataset(file3, drop_variables=[\n",
    "    \"base_time\", \"logger_volt\", \"qc_logger_volt\",\n",
    "    \"logger_temp\", \"qc_logger_temp\", \"lat\",\n",
    "    \"lon\", \"alt\", \"atmos_pressure\", \n",
    "    \"qc_atmos_pressure\", \"temp_mean\", \"qc_temp_mean\",\n",
    "    \"temp_std\", \"rh_mean\", \"qc_rh_mean\",\n",
    "    \"rh_std\", \"vapor_pressure_mean\", \"qc_vapor_pressure_mean\",\n",
    "    \"vapor_pressure_std\", \"wspd_arith_mean\", \"qc_wspd_arith_mean\",\n",
    "    \"wspd_vec_mean\", \"qc_wspd_vec_mean\", \"wdir_vec_mean\",\n",
    "    \"qc_wdir_vec_mean\", \"wdir_vec_std\", \"pws_pw_code_inst\",\n",
    "    \"qc_pws_pw_code_inst\", \"pws_pw_code_15min\", \"qc_pws_pw_code_15min\",\n",
    "    \"pws_pw_code_1hr\", \"qc_pws_pw_code_1hr\", \"pws_precip_rate_mean_1min\",\n",
    "    \"qc_pws_precip_rate_mean_1min\", \"cmh_temp\", \"qc_cmh_temp\",\n",
    "    \"cmh_dew_point\", \"qc_cmh_dew_point\", \"cmh_sat_vapor_pressure\",\n",
    "    \"qc_cmh_sat_vapor_pressure\", \"cmh_vapor_pressure\", \"qc_cmh_vapor_pressure\",\n",
    "    \"cmh_rh\", \"qc_cmh_rh\", \"trh_err_code\",\n",
    "    \"time_offset\"\n",
    "                                            ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Current weather file nsaradflux1longC1.c2.20060114.100000.nc\n",
    "Minute time step solar data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file4 = \"/home/nelson/PycharmProjects/Solar Forecasting Thesis Project/Data_Preperation/test exploration/nsaradflux1longC1.c2.20060114.100000.nc\"\n",
    "ds4 = xr.open_dataset(file4, drop_variables=[\n",
    "    \"time_bounds\", \"base_time\", \"clearsky_downwelling_shortwave\",\n",
    "    \"downwelling_longwave\", \"qc_downwelling_longwave\", \"clearsky_downwelling_longwave\",\n",
    "    \"upwelling_shortwave\", \"qc_upwelling_shortwave\", \"clearsky_upwelling_shortwave\",\n",
    "    \"upwelling_longwave\", \"qc_upwelling_longwave\", \"clearsky_upwelling_longwave\",\n",
    "    \"diffuse_downwelling_shortwave\", \"source_diffuse_downwelling_shortwave\", \"qc_diffuse_downwelling_shortwave\",\n",
    "    \"clearsky_diffuse_downwelling_shortwave\", \"direct_downwelling_shortwave\", \"source_direct_downwelling_shortwave\",\n",
    "    \"qc_direct_downwelling_shortwave\", \"clearsky_direct_downwelling_shortwave\", \"clearsky_status\",\n",
    "    \"cloudfraction_longwave\", \"cloudfraction_shortwave\", \"cloudfraction_shortwave_status\",\n",
    "    \"clearsky_emissivity_longwave\", \"cosine_zenith\", \"cloud_transmissivity_shortwave\",\n",
    "    \"rh_adjustment_to_clearsky_emissivity_longwave\", \"lat\", \"lon\",\n",
    "    \"alt\", \"tau_asymmetry_parameter_status\", \"tau_temperature_limit_status\",\n",
    "    \"ice_cloud_temperature_limit\", \"time_offset\"\n",
    "])\n",
    "\n",
    "df4 = ds4.to_dataframe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}