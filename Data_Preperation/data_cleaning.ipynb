{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data cleanup\n",
    "This will outline the process that I am choosing along with the reasons why\n",
    "I have chosen to further remove variables from my dataset. \n",
    "\n",
    "## Basic Plan\n",
    "I have had some trouble with deciding as to whether or not I should attempt to replace the data the I had missing,\n",
    "replace it with a value that indicates missing data (such as -1), or just remove the data. My thoughts on \n",
    "replacing the data went along the line of using the hourly data that I had to create minute data. Doing this by \n",
    "up-sampling the hourly data. After talking to Dr. Butler though I have instead decided to just drop the rows of missing\n",
    "solar data, including rows where the quality control variable indicates a problem. While replacing all other columns\n",
    "with missing or bad data with a -1 value. That way I only remove essential data rows where forecasting is not a \n",
    "possibility. While at the same time preserving the forecasting potential of the rest of the data.\n",
    "\n",
    "## Entire Variable Removal With Reason\n",
    "Based on year 2007 minute data I have to drop the following variables, reason included.\n",
    "visible_cloud_optical_depth: 82.4% missing data\n",
    "cloud_radiating_temperature: 33.2% missing data\n",
    "\n",
    "All 6 years of training data variables removed\n",
    "\n",
    "Variable name                    Percentage of data missing\n",
    "pwd_cumul_rain                   0.701933\n",
    "pwd_cumul_snow                   0.702052\n",
    "pwd_err_code                     0.682465\n",
    "pwd_mean_vis_10min               0.701172\n",
    "pwd_mean_vis_1min                0.701133\n",
    "pwd_precip_rate_mean_1min        0.701931\n",
    "pwd_pw_code_15min                0.701926\n",
    "pwd_pw_code_1hr                  0.701916\n",
    "pwd_pw_code_inst                 0.701915\n",
    "pws_cumul_rain                   0.361853\n",
    "pws_cumul_snow                   0.361888\n",
    "pws_err_code                     0.330972\n",
    "pws_mean_vis_10min               0.361780\n",
    "pws_mean_vis_1min                0.361782\n",
    "qc_pwd_cumul_rain                0.670197\n",
    "qc_pwd_cumul_snow                0.670197\n",
    "qc_pwd_mean_vis_10min            0.670197\n",
    "qc_pwd_mean_vis_1min             0.670197\n",
    "qc_pwd_precip_rate_mean_1min     0.670197\n",
    "qc_pwd_pw_code_15min             0.670197\n",
    "qc_pwd_pw_code_1hr               0.670197\n",
    "qc_pwd_pw_code_inst              0.670197\n",
    "qc_pws_cumul_rain                0.329803\n",
    "qc_pws_cumul_snow                0.329803\n",
    "qc_pws_mean_vis_10min            0.329803\n",
    "qc_pws_mean_vis_1min             0.329803\n",
    "\n",
    "These variables are being dropped since all that I'm doing for the missing values is inputting a -1\n",
    "\n",
    "\n",
    "\n",
    "## Additional Concerns\n",
    "I believe that before I can remove the missing data rows from the data that I have I need to setup my sliding window.\n",
    "The reason that I think this is that without setting up the sliding window with the correct forecasting time step\n",
    "before I drop the missing or wrong data then I cannot ensure that I have the right forecasting placement. I also think\n",
    "that when I do this I will need to do it to the Validation and Testing datasets at the same time. This way although I\n",
    "don't use those datasets to train my models I have them in the correct format to use them correctly. So I will\n",
    "do that then.\n",
    "\n",
    "\n",
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "# using 2007 as first example. Will check all years\n",
    "df = pd.read_csv(\"/home/nelson/PycharmProjects/Solar Forecasting Thesis Project/\"\n",
    "                 \"Data/train/2007/PreProcessed_data/minute_data_total_year.csv\", index_col=\"time\")\n",
    "df.isnull().sum()  # sums up the missing data \n",
    "\n",
    "df.isnull().sum() / len(df)  # gives percentage of missing data by column\n",
    "\n",
    "def find_null_values_with_continous_threshold(df, column, threshold):\n",
    "    \"\"\"\n",
    "    Function useful for finding continous sections of missing data\n",
    "    \n",
    "    :param df: dataframe\n",
    "    :param column: column name\n",
    "    :param threshold: threshold of missing data to find\n",
    "    :return: nothing\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    index_holder = 0\n",
    "    i = 0\n",
    "    while i < len(df.index) :\n",
    "            if np.isnan(df[column].iloc[i]):\n",
    "                for j in range(i, len(df.index)):\n",
    "                    if count == 0:\n",
    "                        index_holder = i\n",
    "                    if not np.isnan(df[column].iloc[j]):\n",
    "                        count = 0\n",
    "                        index_holder = 0\n",
    "                        break\n",
    "                    count += 1\n",
    "                    if count == threshold:\n",
    "                        print(\"Starts at index \" + df.index[index_holder])\n",
    "                        print(\"10 missing at \" + str(df.index[j]))\n",
    "                    i += 1\n",
    "                count = 0\n",
    "                index_holder = 0\n",
    "            i += 1\n",
    "            "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here I will remove the columns that I have decided should no longer be in the dataset.\n",
    "\n",
    "Add in forecasting column\n",
    "Drop rows with missing solar data or bad quality bits"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# make this whole mess easier and put all training data into one file \n",
    "direct = os.listdir(\"Data/train\")\n",
    "direct.sort()\n",
    "\n",
    "df = []\n",
    "for item in direct:\n",
    "    d = pd.read_csv(\"Data/train/\" + item + \"/PreProcessed_data/minute_data_total_year.csv\", index_col=\"time\")\n",
    "    df.append(d)\n",
    "    \n",
    "df = pd.concat(df)\n",
    "\n",
    "df = df.drop(columns=[\"visible_cloud_optical_depth\", \"cloud_radiating_temperature\",\n",
    "                      \"pwd_cumul_rain\", \"pwd_cumul_snow\",\n",
    "                      \"pwd_err_code\", \"pwd_mean_vis_10min\",\n",
    "                      \"pwd_mean_vis_1min\", \"pwd_precip_rate_mean_1min\",\n",
    "                      \"pwd_pw_code_15min\", \"pwd_pw_code_1hr\",\n",
    "                      \"pwd_pw_code_inst\", \"pws_cumul_rain\",\n",
    "                      \"pws_cumul_snow\", \"pws_err_code\",\n",
    "                      \"pws_mean_vis_10min\", \"pws_mean_vis_1min\",\n",
    "                      \"qc_pwd_cumul_rain\", \"qc_pwd_cumul_snow\",\n",
    "                      \"qc_pwd_mean_vis_10min\", \"qc_pwd_mean_vis_1min\",\n",
    "                      \"qc_pwd_precip_rate_mean_1min\", \"qc_pwd_pw_code_15min\",\n",
    "                      \"qc_pwd_pw_code_1hr\", \"qc_pwd_pw_code_inst\",\n",
    "                      \"qc_pws_cumul_rain\", \"qc_pws_cumul_snow\",\n",
    "                      \"qc_pws_mean_vis_10min\", \"qc_pws_mean_vis_1min\",\n",
    "                      \"qc_time\"])  # dropping vars\n",
    "df[\"forecast_downwelling_shortwave\"] = df[\"downwelling_shortwave\"].shift(20, axis=0)  # shifted values for forecast\n",
    "df[\"qc_forecast_downwelling_shortwave\"] = df[\"qc_downwelling_shortwave\"].shift(20, axis=0)\n",
    "df = df[df[\"qc_downwelling_shortwave\"] == 0]  # removes 7% of the data. \n",
    "df = df[df[\"qc_forecast_downwelling_shortwave\"] == 0] \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Out of the Training data that I have, by removing all of the rows that had a bad quality checker \n",
    "for either the downwelling shortwave or the forecasting downwelling shortwave removed 8.9% of the data.\n",
    "\n",
    "Now I have to remove all other quality checker variables and replace nan values with a -1\n",
    "I am also removing the shortwave quality checker variables."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.drop(columns=['qc_air_temperature', 'qc_dew_point_mean', 'qc_downwelling_shortwave',\n",
    "       'qc_precipitation', 'qc_pressure', 'qc_relative_humidity',\n",
    "       'qc_wind_direction', 'qc_wind_speed', 'qc_forecast_downwelling_shortwave',\n",
    "                      'source_downwelling_shortwave'])\n",
    "\n",
    "df.loc[df[\"downwelling_shortwave\"] < 0, \"downwelling_shortwave\"] = 0  # cast less than 0 values as 0\n",
    "df.loc[df[\"forecast_downwelling_shortwave\"] < 0, \"forecast_downwelling_shortwave\"] = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Null variables by sum. Replacing all values greater that 0 with -1\n",
    "air_temperature                    16020\n",
    "brightness_temperature             15480\n",
    "dew_point_mean                     15812\n",
    "dew_point_std                          0\n",
    "downwelling_shortwave                  0\n",
    "precipitation                     211229\n",
    "pressure                            7468\n",
    "relative_humidity                  18798\n",
    "source_downwelling_shortwave           0\n",
    "vapor_pressure                     18883\n",
    "wind_direction                         0\n",
    "wind_speed                            32\n",
    "forecast_downwelling_shortwave         0\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Start replacing\n",
    "df.loc[df[\"air_temperature\"].isnull(), \"air_temperature\"] = -1\n",
    "df.loc[df[\"brightness_temperature\"].isnull(), \"brightness_temperature\"] = -1\n",
    "df.loc[df[\"dew_point_mean\"].isnull(), \"dew_point_mean\"] = -1\n",
    "df.loc[df[\"precipitation\"].isnull(), \"precipitation\"] = -1\n",
    "df.loc[df[\"pressure\"].isnull(), \"pressure\"] = -1\n",
    "df.loc[df[\"relative_humidity\"].isnull(), \"relative_humidity\"] = -1\n",
    "df.loc[df[\"vapor_pressure\"].isnull(), \"vapor_pressure\"] = -1\n",
    "df.loc[df[\"wind_speed\"].isnull(), \"wind_speed\"] = -1\n",
    "\n",
    "#output to csv \n",
    "df.to_csv(\"Data/train/fully processing minute data.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Further editing needs to to be done to this document mainly to document the change in data for both the testing\n",
    "and validation datasets. Also editing but I think I've now got everything ready to go to run my first \n",
    "forecasting method.\n",
    "\n",
    "train data shape changes\n",
    "3680345, 49\n",
    "3680345, 20\n",
    "3403866, 22\n",
    "3352696, 12\n",
    "\n",
    "\n",
    "Running the same process on testing data at this time in the console. Using this section to keep\n",
    "notes \n",
    "\n",
    "testing data shape changes\n",
    "(1049520, 40)\n",
    "(1043739, 23)\n",
    "(1039841, 23)\n",
    "(1039841, 12)\n",
    "\n",
    "Ok so apparently my testing dataset has a different variables set than my training data\n",
    "So I'm just going to keep all of this in final processing step in the notebook"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Start processing test data\n",
    "\n",
    "direct = os.listdir(\"Data/test\")\n",
    "direct.sort()\n",
    "\n",
    "df = []\n",
    "for item in direct:\n",
    "    d = pd.read_csv(\"Data/test/\" + item + \"/PreProcessed_data/minute_data_total_year.csv\", index_col=\"time\")\n",
    "    df.append(d)\n",
    "df = pd.concat(df)\n",
    "\n",
    "df.shape\n",
    "df = df.drop(columns=[\"visible_cloud_optical_depth\", \"cloud_radiating_temperature\",\n",
    "                      \"pwd_cumul_rain\", \"pwd_cumul_snow\",\n",
    "                      \"pwd_err_code\", \"pwd_mean_vis_10min\",\n",
    "                      \"pwd_mean_vis_1min\", \"pwd_precip_rate_mean_1min\",\n",
    "                      \"pwd_pw_code_15min\", \"pwd_pw_code_1hr\",\n",
    "                      \"pwd_pw_code_inst\", \n",
    "                      \"qc_pwd_cumul_rain\", \"qc_pwd_cumul_snow\",\n",
    "                      \"qc_pwd_mean_vis_10min\", \"qc_pwd_mean_vis_1min\",\n",
    "                      \"qc_pwd_precip_rate_mean_1min\", \"qc_pwd_pw_code_15min\",\n",
    "                      \"qc_pwd_pw_code_1hr\", \"qc_pwd_pw_code_inst\"])  # dropping vars\n",
    "\n",
    "df[\"forecast_downwelling_shortwave\"] = df[\"downwelling_shortwave\"].shift(20, axis=0)  # shifted values for forecast\n",
    "df[\"qc_forecast_downwelling_shortwave\"] = df[\"qc_downwelling_shortwave\"].shift(20, axis=0)\n",
    "df = df[df[\"qc_downwelling_shortwave\"] == 0]  # removes 0.5% of the data. \n",
    "df = df[df[\"qc_forecast_downwelling_shortwave\"] == 0]\n",
    "\n",
    "df = df.drop(columns=['source_downwelling_shortwave',\n",
    "       'qc_downwelling_shortwave', 'qc_wind_speed',\n",
    "                      'qc_wind_direction', 'qc_air_temperature', 'qc_relative_humidity',\n",
    "                      'qc_pressure', 'qc_precipitation', 'qc_dew_point_mean',\n",
    "                      'qc_trh_err_code', 'qc_forecast_downwelling_shortwave'])\n",
    "\n",
    "df.loc[df[\"downwelling_shortwave\"] < 0, \"downwelling_shortwave\"] = 0  # cast less than 0 values as 0\n",
    "df.loc[df[\"forecast_downwelling_shortwave\"] < 0, \"forecast_downwelling_shortwave\"] = 0\n",
    "\n",
    "df.loc[df[\"air_temperature\"].isnull(), \"air_temperature\"] = -1\n",
    "df.loc[df[\"brightness_temperature\"].isnull(), \"brightness_temperature\"] = -1\n",
    "df.loc[df[\"dew_point_mean\"].isnull(), \"dew_point_mean\"] = -1\n",
    "df.loc[df[\"precipitation\"].isnull(), \"precipitation\"] = -1\n",
    "df.loc[df[\"pressure\"].isnull(), \"pressure\"] = -1\n",
    "df.loc[df[\"relative_humidity\"].isnull(), \"relative_humidity\"] = -1\n",
    "df.loc[df[\"vapor_pressure\"].isnull(), \"vapor_pressure\"] = -1\n",
    "df.loc[df[\"wind_speed\"].isnull(), \"wind_speed\"] = -1\n",
    "df.loc[df[\"wind_direction\"].isnull(), \"wind_direction\"] = -1\n",
    "\n",
    "df.to_csv(\"Data/test/fully processes minute data.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Moving and finishing up with Validation data\n",
    "\n",
    "\n",
    "Validation data shape changes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "direct = os.listdir(\"Data/validate\")\n",
    "direct.sort()\n",
    "df = []\n",
    "for item in direct:\n",
    "    d = pd.read_csv(\"Data/validate/\" + item + \"/PreProcessed_data/minute_data_total_year.csv\", index_col=\"time\")\n",
    "    df.append(d)\n",
    "df = pd.concat(df)\n",
    "df.shape\n",
    "\n",
    "df = df.drop(columns=[\"visible_cloud_optical_depth\", \"cloud_radiating_temperature\",\n",
    "                      \"pwd_cumul_rain\", \"pwd_cumul_snow\",\n",
    "                      \"pwd_err_code\", \"pwd_mean_vis_10min\",\n",
    "                      \"pwd_mean_vis_1min\", \"pwd_precip_rate_mean_1min\",\n",
    "                      \"pwd_pw_code_15min\", \"pwd_pw_code_1hr\",\n",
    "                      \"pwd_pw_code_inst\", \n",
    "                      \"qc_pwd_cumul_rain\", \"qc_pwd_cumul_snow\",\n",
    "                      \"qc_pwd_mean_vis_10min\", \"qc_pwd_mean_vis_1min\",\n",
    "                      \"qc_pwd_precip_rate_mean_1min\", \"qc_pwd_pw_code_15min\",\n",
    "                      \"qc_pwd_pw_code_1hr\", \"qc_pwd_pw_code_inst\"])  # dropping vars\n",
    "\n",
    "df[\"forecast_downwelling_shortwave\"] = df[\"downwelling_shortwave\"].shift(20, axis=0)  # shifted values for forecast\n",
    "df[\"qc_forecast_downwelling_shortwave\"] = df[\"qc_downwelling_shortwave\"].shift(20, axis=0)\n",
    "df = df[df[\"qc_downwelling_shortwave\"] == 0]  # removes 10.8% of the data. \n",
    "df = df[df[\"qc_forecast_downwelling_shortwave\"] == 0]\n",
    "\n",
    "df = df.drop(columns=['source_downwelling_shortwave',\n",
    "       'qc_downwelling_shortwave', 'qc_wind_speed',\n",
    "                      'qc_wind_direction', 'qc_air_temperature', 'qc_relative_humidity',\n",
    "                      'qc_pressure', 'qc_precipitation', 'qc_dew_point_mean',\n",
    "                      'qc_trh_err_code', 'qc_forecast_downwelling_shortwave', \"qc_time\"])\n",
    "\n",
    "df.loc[df[\"downwelling_shortwave\"] < 0, \"downwelling_shortwave\"] = 0  # cast less than 0 values as 0\n",
    "df.loc[df[\"forecast_downwelling_shortwave\"] < 0, \"forecast_downwelling_shortwave\"] = 0\n",
    "\n",
    "df.loc[df[\"air_temperature\"].isnull(), \"air_temperature\"] = -1\n",
    "df.loc[df[\"brightness_temperature\"].isnull(), \"brightness_temperature\"] = -1\n",
    "df.loc[df[\"dew_point_mean\"].isnull(), \"dew_point_mean\"] = -1\n",
    "df.loc[df[\"precipitation\"].isnull(), \"precipitation\"] = -1\n",
    "df.loc[df[\"pressure\"].isnull(), \"pressure\"] = -1\n",
    "df.loc[df[\"relative_humidity\"].isnull(), \"relative_humidity\"] = -1\n",
    "df.loc[df[\"vapor_pressure\"].isnull(), \"vapor_pressure\"] = -1\n",
    "df.loc[df[\"wind_speed\"].isnull(), \"wind_speed\"] = -1\n",
    "df.loc[df[\"wind_direction\"].isnull(), \"wind_direction\"] = -1\n",
    "\n",
    "df.to_csv(\"Data/validate/fully processes minute data.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}